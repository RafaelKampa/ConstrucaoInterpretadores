{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelKampa/ConstrucaoInterpretadores/blob/main/Matriz_TF_IDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PHc1cYcE4rS"
      },
      "source": [
        "<h1><b>TRABALHO RECUPERAÇÃO DE TEXTOS – TF-IDF</b></h1>\n",
        "<h2>Alunos: Bernardo Zeni Diniz, Lucas Camargo Vianna, Pedro Leonardo Alves da Silva, Rafael Gilberto Kampa</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH02eeWzHb1f"
      },
      "source": [
        "<h1>Enunciado:</h1>\n",
        "Sua tarefa será gerar a matriz termo documento, usando o algoritmo TF-IDF, dos documentos\n",
        "recuperados da internet e imprimir esta matriz na tela. Para tanto:<br><br>\n",
        "a) Seu algoritmo deve receber um link, para um documento txt, disponível na internet (Projeto Gutenberg - Free eBooks | Project Gutenberg), transformar todas as sentenças deste documento em listas de strings. As sentenças serão limitas por ponto final, dois pontos ou ponto e virgula.<br><br>\n",
        "b) O conjunto de listas de sentenças será o corpus que você irá usar para criar a matriz termo documento usando o algoritmo bag of words.<br><br>\n",
        "c) O resultado esperado será a apresentação da matriz termo documento em uma forma interativa que permita a visualização das linhas e colunas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-T6Oujo1pO8"
      },
      "outputs": [],
      "source": [
        "#Gera um arquivo .txt com a matriz Bag of Words\n",
        "import requests\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "# # Salva o nome do arquivo em uma variável global para futuros usos\n",
        "nome_arquivo_gerado = \"BagOfWords.txt\"\n",
        "\n",
        "# Lê o arquivo de texto do URL fornecido\n",
        "response = requests.get(\"https://www.gutenberg.org/files/53106/53106-8.txt\")\n",
        "texto = response.text\n",
        "\n",
        "# Separa o texto em documentos usando \".\" \",\" \";\" como separadores e substitui \"\\n\" e \"\\r\" por um espaço em branco\n",
        "separadores = [\".\", \",\", \";\"]\n",
        "texto = texto.replace('\\n', ' ').replace('\\r', ' ')\n",
        "documentos = re.split('|'.join(map(re.escape, separadores)), texto)\n",
        "\n",
        "# # Salva o nome do arquivo em uma variável global para futuros usos\n",
        "# nome_arquivo_gerado = \"BagOfWords.txt\"\n",
        "# nome_arquivo_local = \"teste.txt\"\n",
        "\n",
        "# # Lê o arquivo de texto local\n",
        "# with open(nome_arquivo_local, \"r\") as file:\n",
        "#     texto = file.read()\n",
        "\n",
        "# # Separa o texto em documentos usando \".\", \",\", \";\" como separadores e substitui \"\\n\" e \"\\r\" por um espaço em branco\n",
        "# separadores = [\".\", \",\", \";\"]\n",
        "# texto = texto.replace('\\n', ' ').replace('\\r', ' ')\n",
        "# documentos = re.split('|'.join(map(re.escape, separadores)), texto)\n",
        "\n",
        "# Remove os documentos vazios (resultantes de múltiplos caracteres separadores consecutivos)\n",
        "documentos = list(filter(lambda x: len(x) > 0, documentos))\n",
        "\n",
        "# Remove os espaços em branco do início e do final dos documentos\n",
        "documentos = [documento.strip() for documento in documentos]\n",
        "\n",
        "# Cria um set de todas as palavras encontradas nos documentos\n",
        "todas_palavras = set()\n",
        "for documento in documentos:\n",
        "    palavras = documento.split()\n",
        "    for palavra in palavras:\n",
        "        todas_palavras.add(palavra)\n",
        "\n",
        "# Cria um dicionário para contar a frequência de cada palavra em cada documento\n",
        "freq_palavras = {}\n",
        "for i, documento in enumerate(documentos):\n",
        "    palavras = documento.split()\n",
        "    for palavra in palavras:\n",
        "        if palavra not in freq_palavras:\n",
        "            freq_palavras[palavra] = np.zeros(len(documentos), dtype=int)\n",
        "        freq_palavras[palavra][i] += 1\n",
        "\n",
        "# Cria a matriz de frequência\n",
        "matriz = np.zeros((len(documentos), len(todas_palavras)), dtype=int)\n",
        "for j, palavra in enumerate(todas_palavras):\n",
        "    if palavra in freq_palavras:\n",
        "        matriz[:, j] = freq_palavras[palavra]\n",
        "\n",
        "# Remove as linhas com somente zeros\n",
        "linhas_nao_nulas = np.any(matriz, axis=1)\n",
        "matriz = matriz[linhas_nao_nulas]\n",
        "documentos = [documentos[i] for i in range(len(linhas_nao_nulas)) if linhas_nao_nulas[i]]\n",
        "\n",
        "# Cria os rótulos de linhas e colunas\n",
        "rotulos_linhas = np.arange(1, len(documentos)+1, dtype=int).reshape(-1, 1)\n",
        "rotulos_colunas = np.array(list(todas_palavras))\n",
        "\n",
        "# Concatena os rótulos de linhas e colunas e a matriz final\n",
        "matriz_final = np.hstack([np.array([[\"Documento\"]]), rotulos_colunas.reshape(1, -1)])\n",
        "matriz_final = np.vstack([matriz_final, np.hstack([rotulos_linhas, matriz])])\n",
        "\n",
        "# Salva a matriz em um arquivo de texto\n",
        "np.savetxt(nome_arquivo_gerado, matriz_final, delimiter=\";\", fmt=\"%s\")\n",
        "\n",
        "print(\"Arquivo 'BagOfWords.txt' salvo com sucesso.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gera um arquivo .txt com a matriz TF-IDF\n",
        "import numpy as np\n",
        "\n",
        "# Função para calcular o TF-IDF\n",
        "def calculate_tfidf(freq_palavra_doc, termos_doc, num_documentos, freq_termo_doc):\n",
        "    if freq_termo_doc > 0 and freq_palavra_doc > 0:\n",
        "        return (freq_palavra_doc / termos_doc) * np.log(num_documentos / freq_termo_doc)\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Leitura do arquivo de entrada\n",
        "with open('BagOfWords.txt', 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Extração dos dados do arquivo\n",
        "num_documentos = len(lines) - 1\n",
        "num_palavras = len(lines[0].strip().split(';')) - 1\n",
        "rotulos_palavras = lines[0].strip().split(';')[1:]  # Rótulos das palavras\n",
        "rotulos_documentos = [line.strip().split(';')[0] for line in lines[1:]]  # Rótulos dos documentos\n",
        "matriz = np.zeros((num_documentos, num_palavras))\n",
        "\n",
        "for i in range(1, len(lines)):\n",
        "    values = lines[i].strip().split(';')[1:]\n",
        "    for j in range(num_palavras):\n",
        "        freq_palavra_doc = int(values[j])\n",
        "        termos_doc = sum(map(int, values))\n",
        "        freq_termo_doc = sum([1 for line in lines[1:] if int(line.strip().split(';')[j + 1]) > 0])\n",
        "        matriz[i - 1, j] = calculate_tfidf(freq_palavra_doc, termos_doc, num_documentos, freq_termo_doc)\n",
        "\n",
        "# Salvando a matriz de resultados em um novo arquivo\n",
        "with open('TF-IDF.txt', 'w') as file:\n",
        "    file.write('Documento;' + ';'.join(rotulos_palavras) + '\\n')\n",
        "    for i in range(num_documentos):\n",
        "        file.write(rotulos_documentos[i] + ';' + ';'.join(map(str, matriz[i, :])))\n",
        "        file.write('\\n')\n",
        "\n",
        "print(\"Arquivo 'TF-IDF.txt' salvo com sucesso.\")"
      ],
      "metadata": {
        "id": "WLKaYKEEP4-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Salva o nome de arquivo gerado como o novo arquivo em uma variável global para futuros usos\n",
        "nome_arquivo_gerado = \"TF-IDF.txt\""
      ],
      "metadata": {
        "id": "_vnXMI8BQU_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ghUCpv88iz1"
      },
      "outputs": [],
      "source": [
        "# Esta função faz o filtro pela linha informada pelo usuário na matriz .txt gerada anteriormente \n",
        "def ler_matriz(nome_arquivo, num_linha):\n",
        "    with open(nome_arquivo, 'r') as f:\n",
        "        linhas = f.readlines()\n",
        "        valores_linha = linhas[0].strip().split(';')[1:]\n",
        "        valores_retornados = []\n",
        "        for i, valor in enumerate(valores_linha):\n",
        "            coluna = [linha.strip().split(';')[i+1] for linha in linhas[num_linha:num_linha+1]]\n",
        "            valor_int = float(coluna[0])\n",
        "            if valor_int != 0:\n",
        "                valores_retornados += [valor] * int(round(valor_int))\n",
        "        return valores_retornados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JivfEAMH8lhG"
      },
      "outputs": [],
      "source": [
        "# Chama a função anterior e imprime uma lista com as repetições das palavras encontradas naquela linha da matriz gerada anteriormente\n",
        "nome_arquivo = nome_arquivo_gerado\n",
        "num_linha = int(float(input('Digite o número da linha desejada: ')))\n",
        "valores = ler_matriz(nome_arquivo, num_linha)\n",
        "print(valores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXIvtjd0A_g1"
      },
      "outputs": [],
      "source": [
        "# Esta função seleciona o maior valor encontrado dentro da matriz salva em arquivo .txt e retorna a palavra seguido da quantia de usos da mesma\n",
        "def encontrar_maior_valor(nome_arquivo):\n",
        "    with open(nome_arquivo, 'r') as f:\n",
        "        linhas = f.readlines()\n",
        "        valores_linha = linhas[0].strip().split(';')[1:]\n",
        "        maior_valor = float('-inf')\n",
        "        posicoes_maior_valor = []\n",
        "        for i, linha in enumerate(linhas[1:]):\n",
        "            valores = linha.strip().split(';')[1:]\n",
        "            for j, valor in enumerate(valores):\n",
        "                valor_int = float(valor)\n",
        "                if valor_int > maior_valor:\n",
        "                    maior_valor = valor_int\n",
        "                    posicoes_maior_valor = [(i+1, j+1)]  # +1 pois estamos ignorando a primeira linha e coluna\n",
        "                elif valor_int == maior_valor:\n",
        "                    posicoes_maior_valor.append((i+1, j+1))\n",
        "        resultados = []\n",
        "        for posicao in posicoes_maior_valor:\n",
        "            string_maior_valor = valores_linha[posicao[1]-1]  # -1 pois a posição começa em 1\n",
        "            resultados.append(f'{string_maior_valor} = {maior_valor}')\n",
        "        return resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB1yzGMSDDv2",
        "outputId": "b9c026c6-5d62-4953-b252-208df3611d38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['LTD = 8.48446336679332', 'Væring = 8.48446336679332', 'Secondly = 8.48446336679332', '5) = 8.48446336679332', '786-802) = 8.48446336679332', '787 = 8.48446336679332', '66) = 8.48446336679332', '21) = 8.48446336679332', '46-7) = 8.48446336679332', '58) = 8.48446336679332', 'Montgomery) = 8.48446336679332', 'Knútr) = 8.48446336679332', 'York) = 8.48446336679332', \"'Brunanburh = 8.48446336679332\", 'Dumfriesshire = 8.48446336679332', 'ransomed = 8.48446336679332', 'Ghent = 8.48446336679332', 'Amiens = 8.48446336679332', 'Chartres = 8.48446336679332', 'Tours = 8.48446336679332', 'Blois = 8.48446336679332', 'Orléans = 8.48446336679332', 'Poitiers = 8.48446336679332', 'Limoges = 8.48446336679332', 'Berno = 8.48446336679332', 'Coblentz = 8.48446336679332', 'Aachen = 8.48446336679332', 'Later = 8.48446336679332', 'Eiríkr) = 8.48446336679332', 'Lisieux = 8.48446336679332', 'Seez = 8.48446336679332', '912) = 8.48446336679332', 'Ívarr) = 8.48446336679332', '_knúi = 8.48446336679332', 'knúi_ = 8.48446336679332', '57) = 8.48446336679332', '934) = 8.48446336679332', 'SCOTLAND = 8.48446336679332', '_v = 8.48446336679332', '12) = 8.48446336679332', 'Argyle = 8.48446336679332', 'Anglians = 8.48446336679332', 'Goths = 8.48446336679332', 'Dýri) = 8.48446336679332', '19) = 8.48446336679332', 'Ruotsi = 8.48446336679332', '46) = 8.48446336679332', \"'Gunvor = 8.48446336679332\", '36) = 8.48446336679332', 'sacrifice-earl = 8.48446336679332', 'irony = 8.48446336679332', 'chaotic = 8.48446336679332', 'wool = 8.48446336679332', 'youthful = 8.48446336679332', 'bright = 8.48446336679332', 'clinker-built = 8.48446336679332', 'horn = 8.48446336679332', 'glass = 8.48446336679332', 'rock-crystal = 8.48446336679332', 'legs = 8.48446336679332', 'refashioned = 8.48446336679332', 'square = 8.48446336679332', 'Horses = 8.48446336679332', 'dogs = 8.48446336679332', '750 = 8.48446336679332', '85) = 8.48446336679332', 'SHETLANDS = 8.48446336679332', 'MacAulay = 8.48446336679332', '111) = 8.48446336679332', '126-7) = 8.48446336679332', '6) = 8.48446336679332', 'Switzerland = 8.48446336679332', '_ló_ = 8.48446336679332', 'flat-grassland = 8.48446336679332', 'Dalkey = 8.48446336679332', '_höfuð_ = 8.48446336679332', '_eyrr_ = 8.48446336679332', '_kaupmannaeyjar_ = 8.48446336679332', '_laxahlaup_ = 8.48446336679332', \"'salmon-leap = 8.48446336679332\", '97) = 8.48446336679332', 'MacIver = 8.48446336679332', '_Austmaðr_ = 8.48446336679332', 'brook = 8.48446336679332', '-BIGGIN(G) = 8.48446336679332', '_bygging_ = 8.48446336679332', '-BY = 8.48446336679332', '_bør_ = 8.48446336679332', 'Dan = 8.48446336679332', 'Swed = 8.48446336679332', '_by_ = 8.48446336679332', '-CAR(R) = 8.48446336679332', '-ker = 8.48446336679332', '_kjarr_ = 8.48446336679332', '_kjörr_ = 8.48446336679332', 'brushwood = 8.48446336679332', '-DALE = 8.48446336679332', '-FELL = 8.48446336679332', '_fjall_ = 8.48446336679332', '-FORCE = 8.48446336679332', '_fors_ = 8.48446336679332', 'waterfall = 8.48446336679332', '-FORTH = 8.48446336679332', '-GARTH = 8.48446336679332', 'enclosure = 8.48446336679332', '_gil_ = 8.48446336679332', '-HOLM = 8.48446336679332', '_holmr_ = 8.48446336679332', '-KELD = 8.48446336679332', '_kelda_ = 8.48446336679332', '-LUND = 8.48446336679332', '-lound = 8.48446336679332', '-MIRE = 8.48446336679332', '_myrr_ = 8.48446336679332', 'moor = 8.48446336679332', 'bog = 8.48446336679332', '-RAISE = 8.48446336679332', '_hreysi_ = 8.48446336679332', 'cairn = 8.48446336679332', '-SCALE = 8.48446336679332', '_skali_ = 8.48446336679332', '-SCAR = 8.48446336679332', '-skear = 8.48446336679332', '-skerry = 8.48446336679332', '_sker_ = 8.48446336679332', '-SCOUT = 8.48446336679332', '_skúti_ = 8.48446336679332', '-SCOUGH = 8.48446336679332', '-scow = 8.48446336679332', '_skógr_ = 8.48446336679332', '-SLACK = 8.48446336679332', '_slakki_ = 8.48446336679332', '-TARN = 8.48446336679332', '_tjörn_ = 8.48446336679332', '-THORP(E) = 8.48446336679332', 'hamlet = 8.48446336679332', '-THWAITE = 8.48446336679332', 'paddock = 8.48446336679332', '-TOFT = 8.48446336679332', 'messuage = 8.48446336679332', 'homestead = 8.48446336679332', '-WITH = 8.48446336679332', '_viðr_ = 8.48446336679332', '-WATH = 8.48446336679332', '_vað_ = 8.48446336679332', '_Gunnarr_ = 8.48446336679332', '_Ketill_ = 8.48446336679332', '_Klakkr_ = 8.48446336679332', '_Ormr_ = 8.48446336679332', '_Gamall_ = 8.48446336679332', '_Gunnúlfr_ = 8.48446336679332', '_Knútr_ = 8.48446336679332', 'Northants = 8.48446336679332', '_Leifr_ = 8.48446336679332', '_Sumarliði_ = 8.48446336679332', '_Skúli_ = 8.48446336679332', 'Norf = 8.48446336679332', '_Tóli_ = 8.48446336679332', 'Hunts = 8.48446336679332', '_Víkingr_ = 8.48446336679332', 'Leic = 8.48446336679332', '_Úlfr_ = 8.48446336679332', 'Carrs = 8.48446336679332', '_bask_ = 8.48446336679332', '_batten_ = 8.48446336679332', '_call_ = 8.48446336679332', '_cast_ = 8.48446336679332', '_dawn_ = 8.48446336679332', '_droop_ = 8.48446336679332', '_drown_ = 8.48446336679332', '_gain_ = 8.48446336679332', '_gabble_ = 8.48446336679332', '_ransack_ = 8.48446336679332', '_scare_ = 8.48446336679332', '_scour_ = 8.48446336679332', '_scrape_ = 8.48446336679332', '_skim_ = 8.48446336679332', '_skip_ = 8.48446336679332', '_squeal_ = 8.48446336679332', '_stint_ = 8.48446336679332', '_take_ = 8.48446336679332', '_billow_ = 8.48446336679332', '_boon_ = 8.48446336679332', '_dusk_ = 8.48446336679332', '_fellow_ = 8.48446336679332', '_gait_ = 8.48446336679332', '_grime_ = 8.48446336679332', '_haven_ = 8.48446336679332', '_husband_ = 8.48446336679332', '_husk_ = 8.48446336679332', '_husting_ = 8.48446336679332', '_scull_ = 8.48446336679332', '_scurf_ = 8.48446336679332', '_skill_ = 8.48446336679332', '_skin_ = 8.48446336679332', '_skirt_ = 8.48446336679332', '_sky_ = 8.48446336679332', '_window_ = 8.48446336679332', '_ill_ = 8.48446336679332', '_odd_ = 8.48446336679332', '_rotten_ = 8.48446336679332', '_scant_ = 8.48446336679332', '_sly_ = 8.48446336679332', '_ugly_ = 8.48446336679332', '_weak_ = 8.48446336679332', '_aloft_ = 8.48446336679332', '_athwart_ = 8.48446336679332', '_awe_ = 8.48446336679332', '_birth_ = 8.48446336679332', '_egg_ = 8.48446336679332', '_get_ = 8.48446336679332', '_gift_ = 8.48446336679332', '_give_ = 8.48446336679332', '_guest_ = 8.48446336679332', '_raid_ = 8.48446336679332', '_sister_ = 8.48446336679332', '_swain_ = 8.48446336679332', '_Thursday_ = 8.48446336679332', '_þriþjungr_ = 8.48446336679332', '_supra_ = 8.48446336679332', 'Catteville = 8.48446336679332', 'Cauverville = 8.48446336679332', 'Colleville = 8.48446336679332', 'Fouqueville = 8.48446336679332', '_Kálfr_ = 8.48446336679332', '_Kolr_ = 8.48446336679332', '_Fólki_ = 8.48446336679332', '_Hákon_ = 8.48446336679332', '-_beuf_ = 8.48446336679332', '-_dale_ = 8.48446336679332', '-_ey_ = 8.48446336679332', '-_gard_ = 8.48446336679332', '-_londe_ = 8.48446336679332', '-_torp_ = 8.48446336679332', '-_tot_ = 8.48446336679332', '-_tuit_ = 8.48446336679332', 'Elbeuf = 8.48446336679332', 'Saussedalle = 8.48446336679332', 'Jersey = 8.48446336679332', 'Eppegard = 8.48446336679332', 'Mandelonde = 8.48446336679332', 'Torgistorp = 8.48446336679332', 'Abbetot = 8.48446336679332', 'Bracquetuit = 8.48446336679332', '124-5) = 8.48446336679332', '_abet_ = 8.48446336679332', '_baggage_ = 8.48446336679332', '_elope_ = 8.48446336679332', '_equip_ = 8.48446336679332', '_jolly_ = 8.48446336679332', '_rubbish_ = 8.48446336679332', '_scoop_ = 8.48446336679332', 'half-priest = 8.48446336679332', 'half-leader = 8.48446336679332', 'Halle = 8.48446336679332', 'BUGGE = 8.48446336679332', 'Vikingerne = 8.48446336679332', '1904-6 = 8.48446336679332', '1896 = 8.48446336679332', '1905 = 8.48446336679332', 'Pt = 8.48446336679332', 'COLLINGWOOD = 8.48446336679332', 'CRAIGIE = 8.48446336679332', 'DIETRICHSON = 8.48446336679332', '1889 = 8.48446336679332', 'GUSTAFSON = 8.48446336679332', 'HENDERSON = 8.48446336679332', 'Glasgow = 8.48446336679332', 'KEARY = 8.48446336679332', '1891 = 8.48446336679332', 'KERMODE = 8.48446336679332', 'MAURER = 8.48446336679332', 'Munich = 8.48446336679332', '1855-9 = 8.48446336679332', 'MONTELIUS = 8.48446336679332', '1903 = 8.48446336679332', '1897 = 8.48446336679332', 'Strasburg = 8.48446336679332', '1897-8 = 8.48446336679332', 'Normannerne = 8.48446336679332', 'THOMSEN = 8.48446336679332', '1877 = 8.48446336679332', 'VOGEL = 8.48446336679332', 'VOGT = 8.48446336679332', '34 = 8.48446336679332', '60-1 = 8.48446336679332', '76 = 8.48446336679332', '61 = 8.48446336679332', '63-4 = 8.48446336679332', '38-9 = 8.48446336679332', '128-9 = 8.48446336679332', '22-3 = 8.48446336679332', '33-4 = 8.48446336679332', '55 = 8.48446336679332', '59-60 = 8.48446336679332', '14 = 8.48446336679332', '27-8 = 8.48446336679332', '22-43 = 8.48446336679332', '15-8 = 8.48446336679332', '17-21 = 8.48446336679332', '43-53 = 8.48446336679332', '18-9 = 8.48446336679332', '67-8 = 8.48446336679332', 'Hörðai = 8.48446336679332', '12-13 = 8.48446336679332', '54-64 = 8.48446336679332', '54-8 = 8.48446336679332', '59 = 8.48446336679332', '62 = 8.48446336679332', '65-8 = 8.48446336679332', '17 = 8.48446336679332', '83-4 = 8.48446336679332', '52-3 = 8.48446336679332', '79 = 8.48446336679332', '118-9 = 8.48446336679332', '21-4 = 8.48446336679332', '53 = 8.48446336679332', '85-6 = 8.48446336679332', '110-1 = 8.48446336679332', '70 = 8.48446336679332', '96-8 = 8.48446336679332', '71 = 8.48446336679332', '79-80 = 8.48446336679332', '75-80 = 8.48446336679332', '13 = 8.48446336679332', 'Variags = 8.48446336679332', '73 = 8.48446336679332', '54-6 = 8.48446336679332', 'GILES = 8.48446336679332', 'SEWARD = 8.48446336679332', 'Macalister = 8.48446336679332', 'Giles = 8.48446336679332', '(N = 8.48446336679332', 'Z = 8.48446336679332', 'Brasses = 8.48446336679332', 'Ward = 8.48446336679332', 'Hist = 8.48446336679332', 'Eden = 8.48446336679332', 'Theol = 8.48446336679332', '(Berlin) = 8.48446336679332', 'Skeat = 8.48446336679332', 'Craigie = 8.48446336679332', 'Sheppard = 8.48446336679332', 'Henderson = 8.48446336679332', 'Robertson = 8.48446336679332', 'Ph = 8.48446336679332', 'Chaytor = 8.48446336679332', 'Sorley = 8.48446336679332', 'Methodism = 8.48446336679332', 'Workman = 8.48446336679332', 'Lit = 8.48446336679332', 'Rait = 8.48446336679332', 'Judd = 8.48446336679332', 'Doncaster = 8.48446336679332', 'Huxley = 8.48446336679332', 'Coward = 8.48446336679332', 'Spiders = 8.48446336679332', 'Warburton = 8.48446336679332', 'Hewitt = 8.48446336679332', 'Beddard = 8.48446336679332', 'Haddon = 8.48446336679332', 'Duckworth = 8.48446336679332', 'Cole = 8.48446336679332', 'Bonney = 8.48446336679332', 'Searle = 8.48446336679332', 'Davison = 8.48446336679332', 'Keeble = 8.48446336679332', 'Bower = 8.48446336679332', 'Seward = 8.48446336679332', 'Poynting = 8.48446336679332', 'Berry = 8.48446336679332', 'Myers = 8.48446336679332', 'Mech = 8.48446336679332', 'Attwood = 8.48446336679332', 'Harper = 8.48446336679332', 'Ferguson = 8.48446336679332', 'Whyte = 8.48446336679332', 'Brewing = 8.48446336679332', 'Winternitz = 8.48446336679332', 'McL = 8.48446336679332', 'Mann = 8.48446336679332', 'Bourchier = 8.48446336679332', 'Longford = 8.48446336679332', 'Gypsies = 8.48446336679332', 'Aldis = 8.48446336679332', 'Pantomime = 8.48446336679332', 'Kitson = 8.48446336679332', 'Breul = 8.48446336679332', 'Cox = 8.48446336679332', 'Fortescue = 8.48446336679332', 'Bragg = 8.48446336679332', 'Latter = 8.48446336679332', 'Carpenter = 8.48446336679332', 'Gadow = 8.48446336679332', 'Jehu = 8.48446336679332', 'Cantrill = 8.48446336679332', 'Leather = 8.48446336679332', 'Procter = 8.48446336679332', 'reports = 8.48446336679332', 'org/license = 8.48446336679332', 'understand = 8.48446336679332', 'performed = 8.48446336679332', 'viewed = 8.48446336679332', 'display = 8.48446336679332', 'perform = 8.48446336679332', 'compressed = 8.48446336679332', 'However = 8.48446336679332', 'org) = 8.48446336679332', 'viewing = 8.48446336679332', 'incomplete = 8.48446336679332', 'DIRECT = 8.48446336679332', 'INDIRECT = 8.48446336679332', 'CONSEQUENTIAL = 8.48446336679332', 'Alaska = 8.48446336679332']\n"
          ]
        }
      ],
      "source": [
        "# Imprime o resultado da função acima passando o nome do arquivo gerado como parâmetro\n",
        "print(encontrar_maior_valor(nome_arquivo_gerado))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ub6BJZt-F9NE"
      },
      "outputs": [],
      "source": [
        "# Esta função seleciona o menor valor encontrado dentro da matriz salva em arquivo .txt e retorna a palavra seguido da quantia de usos da mesma\n",
        "def encontrar_menor_valor(nome_arquivo):\n",
        "    with open(nome_arquivo, 'r') as f:\n",
        "        linhas = f.readlines()\n",
        "        valores_linha = linhas[0].strip().split(';')[1:]\n",
        "        menor_valor = float('inf')\n",
        "        posicoes_menor_valor = []\n",
        "        for i, linha in enumerate(linhas[1:]):\n",
        "            valores = linha.strip().split(';')[1:]\n",
        "            for j, valor in enumerate(valores):\n",
        "                valor_int = float(valor)\n",
        "                if valor_int > 0 and valor_int < menor_valor:\n",
        "                    menor_valor = valor_int\n",
        "                    posicoes_menor_valor = [(i+1, j+1)]  # +1 pois estamos ignorando a primeira linha e coluna\n",
        "                elif valor_int > 0 and valor_int == menor_valor:\n",
        "                    posicoes_menor_valor.append((i+1, j+1))\n",
        "\n",
        "        resultados = []\n",
        "        for posicao in posicoes_menor_valor:\n",
        "            string_menor_valor = valores_linha[posicao[1]-1]  # -1 pois a posição começa em 1\n",
        "            resultados.append(f'{string_menor_valor} = {menor_valor}')\n",
        "\n",
        "        if resultados:\n",
        "            # Verifica se existem outras posições com o mesmo valor mínimo\n",
        "            for i, linha in enumerate(linhas[1:]):\n",
        "                valores = linha.strip().split(';')[1:]\n",
        "                for j, valor in enumerate(valores):\n",
        "                    if float(valor) == menor_valor and (i+1, j+1) not in posicoes_menor_valor:\n",
        "                        string_menor_valor = valores_linha[j]  # -1 pois a posição começa em 1\n",
        "                        resultados.append(f'{string_menor_valor} = {menor_valor}')\n",
        "            return resultados\n",
        "        else:\n",
        "            return 'Não há valores diferentes de zero na matriz.'\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XtmS54rGTTi",
        "outputId": "0340ce89-e7c6-481b-8979-c41d48bc77fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['and = 0.028277984212815202']\n"
          ]
        }
      ],
      "source": [
        "# Imprime o resultado da função acima passando o nome do arquivo gerado como parâmetro\n",
        "print(encontrar_menor_valor(nome_arquivo_gerado))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_laFosaV2fF"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "# Lê o arquivo de texto do URL fornecido\n",
        "response = requests.get(\"https://www.gutenberg.org/files/53106/53106-8.txt\")\n",
        "texto = response.text\n",
        "\n",
        "# Separa o texto em documentos usando \".\" \",\" \";\" como separadores e substitui \"\\n\" e \"\\r\" por um espaço em branco\n",
        "separadores = [\".\", \",\", \";\"]\n",
        "texto = texto.replace('\\n', ' ').replace('\\r', ' ')\n",
        "documentos = re.split('|'.join(map(re.escape, separadores)), texto)\n",
        "\n",
        "# Remove os documentos vazios (resultantes de múltiplos caracteres separadores consecutivos)\n",
        "documentos = list(filter(lambda x: len(x) > 0, documentos))\n",
        "\n",
        "# Remove os espaços em branco do início e do final dos documentos\n",
        "documentos = [documento.strip() for documento in documentos]\n",
        "\n",
        "# Cria um set de todas as palavras encontradas nos documentos\n",
        "todas_palavras = set()\n",
        "for documento in documentos:\n",
        "    palavras = documento.split()\n",
        "    for palavra in palavras:\n",
        "        todas_palavras.add(palavra)\n",
        "\n",
        "# Cria um dicionário para contar a frequência de cada palavra em cada documento\n",
        "freq_palavras = {}\n",
        "num_palavras_por_linha = np.zeros(len(documentos), dtype=int)\n",
        "for i, documento in enumerate(documentos):\n",
        "    palavras = documento.split()\n",
        "    num_palavras_por_linha[i] = len(palavras)\n",
        "    for palavra in palavras:\n",
        "        if palavra not in freq_palavras:\n",
        "            freq_palavras[palavra] = np.zeros(len(documentos), dtype=int)\n",
        "        freq_palavras[palavra][i] += 1\n",
        "\n",
        "# Cria a matriz de frequência\n",
        "matriz = np.zeros((len(documentos), len(todas_palavras)), dtype=float)\n",
        "num_documentos = len(documentos)\n",
        "for j, palavra in enumerate(todas_palavras):\n",
        "    if palavra in freq_palavras:\n",
        "        for i in range(num_documentos):\n",
        "            freq_palavra_doc = freq_palavras[palavra][i]\n",
        "            termos_doc = len(documentos[i].split())\n",
        "            freq_termo_doc = np.count_nonzero(freq_palavras[palavra])\n",
        "            if freq_termo_doc > 0 and freq_palavra_doc > 0:\n",
        "                matriz[i, j] = (freq_palavra_doc / termos_doc) * np.log(num_documentos / freq_termo_doc)\n",
        "\n",
        "# Remove as colunas com somente zeros\n",
        "colunas_nao_nulas = np.any(matriz, axis=0)\n",
        "matriz = matriz[:, colunas_nao_nulas]\n",
        "todas_palavras = list(todas_palavras)\n",
        "todas_palavras = [todas_palavras[i] for i in range(len(colunas_nao_nulas)) if colunas_nao_nulas[i]]\n",
        "\n",
        "# Calcula a soma de cada documento\n",
        "documentos_soma = np.sum(matriz, axis=1)\n",
        "\n",
        "# Calcula as similaridades entre os documentos usando a fórmula do cosseno\n",
        "sim_matrix = np.zeros((num_documentos, num_documentos))\n",
        "for i in range(num_documentos):\n",
        "    for j in range(num_documentos):\n",
        "        if i != j and np.linalg.norm(matriz[i])>0 and np.linalg.norm(matriz[j])>0:#modificado, estou testando\n",
        "            sim_matrix[i, j] = np.dot(matriz[i], matriz[j]) / (np.linalg.norm(matriz[i]) * np.linalg.norm(matriz[j]))\n",
        "        else:\n",
        "            sim_matrix[i, j] =0\n",
        "\n",
        "# Transpõe a matriz para ter cada coluna como um documento\n",
        "matriz_transposta = matriz.T\n",
        "\n",
        "# Cria um array para armazenar as somas de cada documento\n",
        "somas_documentos = np.zeros((len(documentos),), dtype=float)\n",
        "\n",
        "# Calcula a soma de cada documento\n",
        "for i in range(len(documentos)):\n",
        "    somas_documentos[i] = np.sum(matriz[i])\n",
        "\n",
        "# Cria a matriz de similaridade de cosseno\n",
        "matriz_similaridade = np.zeros((len(documentos), len(documentos)), dtype=float)\n",
        "\n",
        "# Calcula a similaridade de cosseno entre cada par de documentos\n",
        "for i in range(len(documentos)):\n",
        "    for j in range(len(documentos)):\n",
        "        if i != j:\n",
        "            cos_sim = np.dot(matriz_transposta[i], matriz_transposta[j]) / (np.linalg.norm(matriz_transposta[i]) * np.linalg.norm(matriz_transposta[j]))\n",
        "            matriz_similaridade[i][j] = cos_sim\n",
        "\n",
        "# Define o valor da diagonal principal como 0\n",
        "np.fill_diagonal(matriz_similaridade, 0)\n",
        "\n",
        "# Salva a matriz em um arquivo de texto\n",
        "np.savetxt('matriz.txt', matriz_similaridade, delimiter=\";\", fmt=\"%s\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}