{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMWlwT8JFLvnhH1hXVZPBr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelKampa/ConstrucaoInterpretadores/blob/main/CosSImilarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>TRABALHO RECUPERAÇÃO DE TEXTOS – TF-IDF</b></h1>\n",
        "<h2>Alunos: Bernardo Zeni Diniz, Lucas Camargo Vianna, Pedro Leonardo Alves da Silva, Rafael Gilberto Kampa</h2>\n"
      ],
      "metadata": {
        "id": "HN5Q0wvdSyap"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>ENUNCIADO</h1>\n",
        "<br>\n",
        "Sua tarefa será gerar uma matriz de cossenos dos ângulos entre todos os vetores criados na matriz termo documento, criada com o algoritmo Tf-Idf. As colunas desta matriz serão números que indiquem o documento que criou o vetor (sentença original). Da mesma forma, as linhas desta matriz serão identificadas por números que identifiquem o documento que criou o vetor (senteça) original. Desta forma teremos uma matriz quadrada cujo lado é igual ao número de vetores que você criou e cuja diagonal será zero.\n"
      ],
      "metadata": {
        "id": "65o-ICqwS8tw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buS1WJzn7onr",
        "outputId": "6bcd8cd3-afa9-4382-bd61-f580d4c179df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo 'BagOfWords.txt' salvo com sucesso.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "# # Salva o nome do arquivo em uma variável global para futuros usos\n",
        "nome_arquivo_gerado = \"BagOfWords.txt\"\n",
        "\n",
        "# Lê o arquivo de texto do URL fornecido\n",
        "response = requests.get(\"https://www.gutenberg.org/files/53106/53106-8.txt\")\n",
        "texto = response.text\n",
        "\n",
        "# Separa o texto em documentos usando \".\" \",\" \";\" como separadores e substitui \"\\n\" e \"\\r\" por um espaço em branco\n",
        "separadores = [\".\", \",\", \";\"]\n",
        "texto = texto.replace('\\n', ' ').replace('\\r', ' ')\n",
        "documentos = re.split('|'.join(map(re.escape, separadores)), texto)\n",
        "\n",
        "# # Salva o nome do arquivo em uma variável global para futuros usos\n",
        "# nome_arquivo_gerado = \"BagOfWords.txt\"\n",
        "# nome_arquivo_local = \"teste.txt\"\n",
        "\n",
        "# # Lê o arquivo de texto local\n",
        "# with open(nome_arquivo_local, \"r\") as file:\n",
        "#     texto = file.read()\n",
        "\n",
        "# # Separa o texto em documentos usando \".\", \",\", \";\" como separadores e substitui \"\\n\" e \"\\r\" por um espaço em branco\n",
        "# separadores = [\".\", \",\", \";\"]\n",
        "# texto = texto.replace('\\n', ' ').replace('\\r', ' ')\n",
        "# documentos = re.split('|'.join(map(re.escape, separadores)), texto)\n",
        "\n",
        "# Remove os documentos vazios (resultantes de múltiplos caracteres separadores consecutivos)\n",
        "documentos = list(filter(lambda x: len(x) > 0, documentos))\n",
        "\n",
        "# Remove os espaços em branco do início e do final dos documentos\n",
        "documentos = [documento.strip() for documento in documentos]\n",
        "\n",
        "# Cria um set de todas as palavras encontradas nos documentos\n",
        "todas_palavras = set()\n",
        "for documento in documentos:\n",
        "    palavras = documento.split()\n",
        "    for palavra in palavras:\n",
        "        todas_palavras.add(palavra)\n",
        "\n",
        "# Cria um dicionário para contar a frequência de cada palavra em cada documento\n",
        "freq_palavras = {}\n",
        "for i, documento in enumerate(documentos):\n",
        "    palavras = documento.split()\n",
        "    for palavra in palavras:\n",
        "        if palavra not in freq_palavras:\n",
        "            freq_palavras[palavra] = np.zeros(len(documentos), dtype=int)\n",
        "        freq_palavras[palavra][i] += 1\n",
        "\n",
        "# Cria a matriz de frequência\n",
        "matriz = np.zeros((len(documentos), len(todas_palavras)), dtype=int)\n",
        "for j, palavra in enumerate(todas_palavras):\n",
        "    if palavra in freq_palavras:\n",
        "        matriz[:, j] = freq_palavras[palavra]\n",
        "\n",
        "# Remove as linhas com somente zeros\n",
        "linhas_nao_nulas = np.any(matriz, axis=1)\n",
        "matriz = matriz[linhas_nao_nulas]\n",
        "documentos = [documentos[i] for i in range(len(linhas_nao_nulas)) if linhas_nao_nulas[i]]\n",
        "\n",
        "# Cria os rótulos de linhas e colunas\n",
        "rotulos_linhas = np.arange(1, len(documentos)+1, dtype=int).reshape(-1, 1)\n",
        "rotulos_colunas = np.array(list(todas_palavras))\n",
        "\n",
        "# Concatena os rótulos de linhas e colunas e a matriz final\n",
        "matriz_final = np.hstack([np.array([[\"Documento\"]]), rotulos_colunas.reshape(1, -1)])\n",
        "matriz_final = np.vstack([matriz_final, np.hstack([rotulos_linhas, matriz])])\n",
        "\n",
        "# Salva a matriz em um arquivo de texto\n",
        "np.savetxt(nome_arquivo_gerado, matriz_final, delimiter=\";\", fmt=\"%s\")\n",
        "\n",
        "print(\"Arquivo 'BagOfWords.txt' salvo com sucesso.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Função para calcular o TF-IDF\n",
        "def calculate_tfidf(freq_palavra_doc, termos_doc, num_documentos, freq_termo_doc):\n",
        "    if freq_termo_doc > 0 and freq_palavra_doc > 0:\n",
        "        return (freq_palavra_doc / termos_doc) * np.log(num_documentos / freq_termo_doc)\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Leitura do arquivo de entrada\n",
        "with open('BagOfWords.txt', 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Extração dos dados do arquivo\n",
        "num_documentos = len(lines) - 1\n",
        "num_palavras = len(lines[0].strip().split(';')) - 1\n",
        "rotulos_palavras = lines[0].strip().split(';')[1:]  # Rótulos das palavras\n",
        "rotulos_documentos = [line.strip().split(';')[0] for line in lines[1:]]  # Rótulos dos documentos\n",
        "matriz = np.zeros((num_documentos, num_palavras))\n",
        "\n",
        "for i in range(1, len(lines)):\n",
        "    values = lines[i].strip().split(';')[1:]\n",
        "    for j in range(num_palavras):\n",
        "        freq_palavra_doc = int(values[j])\n",
        "        termos_doc = sum(map(int, values))\n",
        "        freq_termo_doc = sum([1 for line in lines[1:] if int(line.strip().split(';')[j + 1]) > 0])\n",
        "        matriz[i - 1, j] = calculate_tfidf(freq_palavra_doc, termos_doc, num_documentos, freq_termo_doc)\n",
        "\n",
        "# Salvando a matriz de resultados em um novo arquivo\n",
        "with open('TF-IDF.txt', 'w') as file:\n",
        "    file.write('Documento;' + ';'.join(rotulos_palavras) + '\\n')\n",
        "    for i in range(num_documentos):\n",
        "        file.write(rotulos_documentos[i] + ';' + ';'.join(map(str, matriz[i, :])))\n",
        "        file.write('\\n')\n",
        "\n",
        "print(\"Arquivo 'TF-IDF.txt' salvo com sucesso.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "d1aw4OVb9OWJ",
        "outputId": "9cde9a82-038f-4e6f-eaba-f5188d179383"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-2e8a42e9ecb7>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mfreq_palavra_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtermos_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mfreq_termo_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mmatriz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_tfidf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq_palavra_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtermos_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_documentos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq_termo_doc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-2e8a42e9ecb7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mfreq_palavra_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtermos_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mfreq_termo_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mmatriz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_tfidf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq_palavra_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtermos_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_documentos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq_termo_doc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Carregar a matriz do arquivo de texto\n",
        "data = np.genfromtxt('TF-IDF.txt', delimiter=';', skip_header=1)\n",
        "matrix = data[:, 1:]\n",
        "\n",
        "# Calcula a similaridade para cada par de vetores\n",
        "rows, cols = matrix.shape\n",
        "similarity_matrix = np.zeros((rows + 1, rows + 1), dtype=object)\n",
        "\n",
        "# Adicionar rótulos nas linhas e colunas\n",
        "document_numbers = np.arange(rows)  # Números de documento\n",
        "similarity_matrix[1:, 0] = document_numbers.astype(int)  # Rótulos na primeira coluna (convertidos para inteiros)\n",
        "similarity_matrix[0, 1:] = document_numbers.astype(int)  # Rótulos na primeira linha (convertidos para inteiros)\n",
        "\n",
        "for i in range(1, rows + 1):\n",
        "    for j in range(1, rows + 1):\n",
        "        similarity_matrix[i, j] = \"{:.5f}\".format(np.dot(matrix[i - 1], matrix[j - 1]) / (np.linalg.norm(matrix[i - 1]) * np.linalg.norm(matrix[j - 1])))\n",
        "\n",
        "# Salvar a matriz de similaridade em um novo arquivo de texto\n",
        "np.savetxt('CosSimilarity.txt', similarity_matrix, delimiter=';', fmt='%s')\n",
        "\n",
        "print(\"Arquivo 'CosSimilarity.txt' salvo com sucesso.\")"
      ],
      "metadata": {
        "id": "pNG-iHzWMas5"
      },
      "execution_count": 41,
      "outputs": []
    }
  ]
}